# -*- coding: utf-8 -*-
"""python program remove duplicate data in csv.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C-KQUDHMC4jL2g3mBtQtYvjDkBz6WjUc
"""

import pandas as pd

#step 1 read the csv file
def read_csv_file(file_path):
    df = pd.read_csv(file_path)
    return df

# Step 2: identify and print duplicate records
def find_duplicate_records(df):
    duplicate_records = df[df.duplicated()]
    print("Duplicate records:")
    print(duplicate_records)
    return duplicate_records

# Step 3: remove duplicate records
def remove_duplicate_records(df, duplicate_records):
    df_cleaned = df.drop_duplicates()
    return df_cleaned

#step 4: save the update data to a new CSV file
def save_to_csv(df, output_file):
    df.to_csv(output_file, index=False)
    print(f"Updated CSV file data saved to {output_file}")

#Main execution
if __name__ == "__main__":
    # Input and output file paths
    input_file_path = "file.csv"
    output_file_path = "updatefile.csv"

    #Read the CSV file
    data = read_csv_file(input_file_path)

    #Find and print duplicate records
    duplicate_records = find_duplicate_records(data)

    #Remove duplicate records
    cleaned_data = remove_duplicate_records(data, duplicate_records)

    #Save the updated data to a new CSV file
    save_to_csv(cleaned_data, output_file_path)

