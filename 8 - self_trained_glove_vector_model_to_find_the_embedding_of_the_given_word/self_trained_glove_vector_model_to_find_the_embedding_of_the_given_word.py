# -*- coding: utf-8 -*-
"""self_trained_Glove_vector_model_to_find_the_embedding_of_the_given_word.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GJwkn_6AGcIaMCP8geI8O5Glulwz2ydz
"""

!pip install gensim -q

!pip install nltk -q

from gensim.models import Word2Vec
import nltk
import gensim.downloader as api
from nltk.corpus import stopwords

# Download NLTK data if not already present

nltk.download('stopwords') # Download the stopwords resource

# Tokenize sentences for english words
tokenized_corpus = [nltk.word_tokenize(sent.lower()) for sent in stopwords.words('english')]

print(tokenized_corpus)

model=Word2Vec(sentences=tokenized_corpus,vector_size=50,window=5,min_count=1,workers=4)

word="has"

if word in model.wv:
  embedding=model.wv[word]
  print(f"Embedding for '{word}':\n{embedding}")
else:
  print(f"Word '{word}' not in vocabulary.")